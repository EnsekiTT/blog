{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 音声のコンテキストからパラメータを推測する\n",
    "## 諸々Import (CPUで動くはず)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers\n",
    "from chainer import serializers, cuda\n",
    "xp = cuda.cupy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンテキストとパラメータの学習データを読み込む\n",
    "問題設定: コンテキストの情報からパラメータを予測する\n",
    "\n",
    "これができると何ができるのか？: \n",
    "* 形態素解析などでコンテキストを作成する\n",
    "* コンテキストからパラメータを推測する←今日ここ\n",
    "* パラメータから音声を作成する\n",
    "* うわあああああしゃべったあああああああ\n",
    "-----\n",
    "メモ\n",
    "* コンテキストとは、先行、当該、後続、アクセント句長、アクセント句位置、アクセント型、フレーム数の7次元からなる。\n",
    "* パラメータとは、基本周波数とメルケプストラムの27次元からなる。\n",
    "(本来、コンテキストに対してパラメータは可変長になるが、長さの予測は行わず、学習時に対応するフレーム数を導入することで対応関係を取ることにした。)\n",
    "\n",
    "### 学習・評価データの形式\n",
    "* [先行, 当該, 後続, アクセント句長, アクセント句位置,　アクセント型, フレーム数,　基本周波数, メルケプストラム[0...25]]\n",
    "* [phoneme0, phoneme1, phoneme2, accent_len, accent_pos,　accent_type, frame_num,　f0, mcep[0...25]]\n",
    "\n",
    "### 使ってみるときの形式\n",
    "* [先行, 当該, 後続, アクセント句長, アクセント句位置,　アクセント型, フレーム数]\n",
    "* [phoneme0, phoneme1, phoneme2, accent_len, accent_pos,　accent_type, frame_num]\n",
    "\n",
    "### 使ってみた時に出てくる形式\n",
    "* [基本周波数, メルケプストラム[0...25]]\n",
    "* [f0, mcep[0...25]]\n",
    "\n",
    "### datasディレクトリに諸々入れて使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音素の変換テーブル\n",
    "#　モデルの読み込みに使う。\n",
    "with open('onso.pickle', 'rb') as i:\n",
    "    onso_table = pickle.load(i)\n",
    "# 学習データとテストデータを読み込む\n",
    "\n",
    "try:\n",
    "    contexts_train_csv = pd.read_csv('datas/train.csv', header=None) # ←ここに学習用のテキストデータを渡すと\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "\n",
    "test_path = \"datas/UEM_091.lab\" # ←ここにUEM_091.labを渡すと UEM_091.lab.paramが生成される\n",
    "try:\n",
    "    contexts_test_csv = pd.read_csv(test_path, header=None) \n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phoneme0</th>\n",
       "      <th>phoneme1</th>\n",
       "      <th>phoneme2</th>\n",
       "      <th>accent_len</th>\n",
       "      <th>accent_pos</th>\n",
       "      <th>accent_type</th>\n",
       "      <th>frame_num</th>\n",
       "      <th>f0</th>\n",
       "      <th>mcep0</th>\n",
       "      <th>mcep1</th>\n",
       "      <th>...</th>\n",
       "      <th>mcep16</th>\n",
       "      <th>mcep17</th>\n",
       "      <th>mcep18</th>\n",
       "      <th>mcep19</th>\n",
       "      <th>mcep20</th>\n",
       "      <th>mcep21</th>\n",
       "      <th>mcep22</th>\n",
       "      <th>mcep23</th>\n",
       "      <th>mcep24</th>\n",
       "      <th>mcep25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>0.456265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019452</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>-0.012505</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>0.045686</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>-0.151013</td>\n",
       "      <td>-0.115716</td>\n",
       "      <td>-0.163912</td>\n",
       "      <td>-0.080456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.433629</td>\n",
       "      <td>0.324613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047829</td>\n",
       "      <td>0.130855</td>\n",
       "      <td>-0.063560</td>\n",
       "      <td>0.033953</td>\n",
       "      <td>0.030672</td>\n",
       "      <td>-0.013612</td>\n",
       "      <td>-0.234040</td>\n",
       "      <td>-0.031978</td>\n",
       "      <td>-0.100765</td>\n",
       "      <td>-0.225542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.493183</td>\n",
       "      <td>0.337381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113755</td>\n",
       "      <td>0.164137</td>\n",
       "      <td>-0.175271</td>\n",
       "      <td>0.068837</td>\n",
       "      <td>0.074774</td>\n",
       "      <td>-0.096105</td>\n",
       "      <td>-0.062341</td>\n",
       "      <td>0.062833</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>-0.156493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.537887</td>\n",
       "      <td>0.220762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134378</td>\n",
       "      <td>0.168410</td>\n",
       "      <td>-0.067635</td>\n",
       "      <td>0.114970</td>\n",
       "      <td>0.170909</td>\n",
       "      <td>-0.030111</td>\n",
       "      <td>0.040802</td>\n",
       "      <td>-0.067689</td>\n",
       "      <td>-0.100786</td>\n",
       "      <td>-0.049495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.501573</td>\n",
       "      <td>0.188340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033314</td>\n",
       "      <td>0.019883</td>\n",
       "      <td>0.075013</td>\n",
       "      <td>0.149588</td>\n",
       "      <td>0.076710</td>\n",
       "      <td>0.116201</td>\n",
       "      <td>0.102792</td>\n",
       "      <td>0.035638</td>\n",
       "      <td>-0.067440</td>\n",
       "      <td>0.040577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   phoneme0  phoneme1  phoneme2  accent_len  accent_pos  accent_type  \\\n",
       "0        29        14         1    0.133333    0.066667          0.0   \n",
       "1        29        14         1    0.133333    0.066667          0.0   \n",
       "2        29        14         1    0.133333    0.066667          0.0   \n",
       "3        29        14         1    0.133333    0.066667          0.0   \n",
       "4        29        14         1    0.133333    0.066667          0.0   \n",
       "\n",
       "   frame_num   f0     mcep0     mcep1    ...       mcep16    mcep17    mcep18  \\\n",
       "0   0.006667  0.0 -0.648539  0.456265    ...     0.019452  0.004019 -0.012505   \n",
       "1   0.013333  0.0 -0.433629  0.324613    ...     0.047829  0.130855 -0.063560   \n",
       "2   0.020000  0.0 -0.493183  0.337381    ...     0.113755  0.164137 -0.175271   \n",
       "3   0.026667  0.0 -0.537887  0.220762    ...     0.134378  0.168410 -0.067635   \n",
       "4   0.033333  0.0 -0.501573  0.188340    ...    -0.033314  0.019883  0.075013   \n",
       "\n",
       "     mcep19    mcep20    mcep21    mcep22    mcep23    mcep24    mcep25  \n",
       "0 -0.003931  0.045686  0.116717 -0.151013 -0.115716 -0.163912 -0.080456  \n",
       "1  0.033953  0.030672 -0.013612 -0.234040 -0.031978 -0.100765 -0.225542  \n",
       "2  0.068837  0.074774 -0.096105 -0.062341  0.062833  0.002481 -0.156493  \n",
       "3  0.114970  0.170909 -0.030111  0.040802 -0.067689 -0.100786 -0.049495  \n",
       "4  0.149588  0.076710  0.116201  0.102792  0.035638 -0.067440  0.040577  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_len = contexts_train_csv.shape[0]\n",
    "contexts_train = pd.DataFrame()\n",
    "contexts_train['phoneme0'] = np.array([onso_table[r] for r in contexts_train_csv[0]])\n",
    "contexts_train['phoneme1'] = np.array([onso_table[r] for r in contexts_train_csv[1]])\n",
    "contexts_train['phoneme2'] = np.array([onso_table[r] for r in contexts_train_csv[2]])\n",
    "contexts_train['accent_len'] = contexts_train_csv[3]/15\n",
    "contexts_train['accent_pos'] = contexts_train_csv[4]/15\n",
    "contexts_train['accent_type'] = contexts_train_csv[5]/15\n",
    "contexts_train['frame_num'] = contexts_train_csv[6]/150\n",
    "contexts_train['f0'] = np.log(contexts_train_csv[7]+1)\n",
    "for i in range(26):\n",
    "    contexts_train['mcep'+str(i)] = contexts_train_csv[8+i]\n",
    "\n",
    "contexts_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naIiISGgKGiIiEpqChoiIhKagISIiof1/ClqEwI9aHLIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1d7b81ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log(contexts_train['f0']+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phoneme0</th>\n",
       "      <th>phoneme1</th>\n",
       "      <th>phoneme2</th>\n",
       "      <th>accent_len</th>\n",
       "      <th>accent_pos</th>\n",
       "      <th>accent_type</th>\n",
       "      <th>frame_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phoneme0  phoneme1  phoneme2  accent_len  accent_pos  accent_type  \\\n",
       "0  0.966667  0.166667  0.533333    0.333333    0.066667          0.2   \n",
       "1  0.966667  0.166667  0.533333    0.333333    0.066667          0.2   \n",
       "2  0.966667  0.166667  0.533333    0.333333    0.066667          0.2   \n",
       "3  0.966667  0.166667  0.533333    0.333333    0.066667          0.2   \n",
       "4  0.966667  0.166667  0.533333    0.333333    0.066667          0.2   \n",
       "\n",
       "   frame_num  \n",
       "0   0.006667  \n",
       "1   0.013333  \n",
       "2   0.020000  \n",
       "3   0.026667  \n",
       "4   0.033333  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_len = contexts_test_csv.shape[0]\n",
    "contexts_test = pd.DataFrame()\n",
    "contexts_test['phoneme0'] = np.array([onso_table[r] for r in contexts_test_csv[0]])/30\n",
    "contexts_test['phoneme1'] = np.array([onso_table[r] for r in contexts_test_csv[1]])/30\n",
    "contexts_test['phoneme2'] = np.array([onso_table[r] for r in contexts_test_csv[2]])/30\n",
    "contexts_test['accent_len'] = contexts_test_csv[3]/15\n",
    "contexts_test['accent_pos'] = contexts_test_csv[4]/15\n",
    "contexts_test['accent_type'] = contexts_test_csv[5]/15\n",
    "contexts_test['frame_num'] = contexts_test_csv[6]/150\n",
    "contexts_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare network\n",
    "# n_inは入力ベクトル長\n",
    "# n_outは出力ベクトル長\n",
    "# 良い手段かわからないけど倍ずつ大きくして、最後27次元に落とす\n",
    "# 一応毎回BatchNormalizationする。\n",
    "class context2params(chainer.Chain):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(context2params, self).__init__(\n",
    "            l1=L.Linear(n_in, 14),\n",
    "            l2=L.Linear(14, 28),\n",
    "            l3=L.Linear(28, 56),\n",
    "            l4=L.Linear(56, n_out),\n",
    "            bn1 = L.BatchNormalization(14),\n",
    "            bn2 = L.BatchNormalization(28),\n",
    "            bn3 = L.BatchNormalization(56),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.bn1(self.l1(x)))\n",
    "        h2 = F.relu(self.bn2(self.l2(h1)))\n",
    "        h3 = F.relu(self.bn3(self.l3(h2)))\n",
    "        y = self.l4(h3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・評価データセットを切り分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80%を学習に使って20％を学習の評価に使う。\n",
    "contexts_train_sample = contexts_train.sample(frac=1)\n",
    "N = int(len(contexts_train)*0.8)\n",
    "N_test = len(contexts_train)-N\n",
    "x_train = contexts_train.iloc[:N, 0:7].values.astype(xp.float32)\n",
    "x_test = contexts_train.iloc[N:, 0:7].values.astype(xp.float32)\n",
    "y_train = contexts_train.iloc[:N, 7:].values.astype(xp.float32)\n",
    "y_test = contexts_train.iloc[N:, 7:].values.astype(xp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークとオプティマイザを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワーク\n",
    "model = context2params(7, 27)\n",
    "gpu_device = 0\n",
    "cuda.get_device(gpu_device).use()\n",
    "model.to_gpu(gpu_device)\n",
    "\n",
    "# 最適化\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100\n",
      "train mean loss=24.847913259124674\n",
      "test  mean loss=12.577761710316084\n",
      "epoch 200\n",
      "train mean loss=23.770819652173298\n",
      "test  mean loss=16.00720233572316\n",
      "epoch 300\n",
      "train mean loss=23.331794393994432\n",
      "test  mean loss=18.414956975229437\n",
      "epoch 400\n",
      "train mean loss=23.422317709914182\n",
      "test  mean loss=19.838232393009577\n",
      "epoch 500\n",
      "train mean loss=22.814166543631238\n",
      "test  mean loss=22.862010248390114\n",
      "epoch 600\n",
      "train mean loss=22.256477625780455\n",
      "test  mean loss=23.847220174646118\n",
      "epoch 700\n",
      "train mean loss=22.245688806802946\n",
      "test  mean loss=24.848305787291896\n",
      "epoch 800\n",
      "train mean loss=21.12741128452549\n",
      "test  mean loss=29.084618519760152\n",
      "epoch 900\n",
      "train mean loss=21.898663744768125\n",
      "test  mean loss=25.91465725162996\n",
      "epoch 1000\n",
      "train mean loss=21.96635589642778\n",
      "test  mean loss=28.690377397596073\n",
      "epoch 1100\n",
      "train mean loss=21.628385439136085\n",
      "test  mean loss=33.4604271771652\n",
      "epoch 1200\n",
      "train mean loss=21.65906163380565\n",
      "test  mean loss=27.908760132836353\n",
      "epoch 1300\n",
      "train mean loss=21.182312542699265\n",
      "test  mean loss=35.41176308701674\n",
      "epoch 1400\n",
      "train mean loss=21.587471547869374\n",
      "test  mean loss=33.55020976842817\n",
      "epoch 1500\n",
      "train mean loss=21.414064752932326\n",
      "test  mean loss=32.80140780054624\n",
      "epoch 1600\n",
      "train mean loss=21.46952967990391\n",
      "test  mean loss=34.84062225285917\n",
      "epoch 1700\n",
      "train mean loss=20.550184034067446\n",
      "test  mean loss=33.17205643315835\n",
      "epoch 1800\n",
      "train mean loss=20.783563497368938\n",
      "test  mean loss=33.523438857093325\n",
      "epoch 1900\n",
      "train mean loss=21.03549227263094\n",
      "test  mean loss=34.796954310276284\n",
      "epoch 2000\n",
      "train mean loss=21.37587553795145\n",
      "test  mean loss=33.24898972935713\n",
      "epoch 2100\n",
      "train mean loss=21.3570403829327\n",
      "test  mean loss=36.46571556506256\n",
      "epoch 2200\n",
      "train mean loss=21.013930993081182\n",
      "test  mean loss=35.1409633910512\n",
      "epoch 2300\n",
      "train mean loss=20.852297941832802\n",
      "test  mean loss=42.059732999554164\n",
      "epoch 2400\n",
      "train mean loss=21.249015167820968\n",
      "test  mean loss=36.95450512656142\n",
      "epoch 2500\n",
      "train mean loss=21.364457519784366\n",
      "test  mean loss=39.92559647927367\n",
      "epoch 2600\n",
      "train mean loss=20.559387202753513\n",
      "test  mean loss=40.52432045787599\n",
      "epoch 2700\n",
      "train mean loss=20.4098631752104\n",
      "test  mean loss=42.01121179180723\n",
      "epoch 2800\n",
      "train mean loss=20.73141206125287\n",
      "test  mean loss=41.89501432918238\n",
      "epoch 2900\n",
      "train mean loss=20.812389200185375\n",
      "test  mean loss=43.12766820459426\n",
      "epoch 3000\n",
      "train mean loss=20.60686277471025\n",
      "test  mean loss=42.78620553841925\n",
      "epoch 3100\n",
      "train mean loss=20.60134226189721\n",
      "test  mean loss=42.418810644365536\n",
      "epoch 3200\n",
      "train mean loss=20.679011987952524\n",
      "test  mean loss=41.613503175390676\n",
      "epoch 3300\n",
      "train mean loss=20.108312271478745\n",
      "test  mean loss=42.606949639428876\n",
      "epoch 3400\n",
      "train mean loss=20.09218281409352\n",
      "test  mean loss=45.167577317460875\n",
      "epoch 3500\n",
      "train mean loss=20.25233752337165\n",
      "test  mean loss=42.23531880517275\n",
      "epoch 3600\n",
      "train mean loss=20.352784914988916\n",
      "test  mean loss=41.63186986087897\n",
      "epoch 3700\n",
      "train mean loss=20.079078454169498\n",
      "test  mean loss=43.18599500029929\n",
      "epoch 3800\n",
      "train mean loss=20.376440302214878\n",
      "test  mean loss=45.393801920190285\n",
      "epoch 3900\n",
      "train mean loss=20.293134873521502\n",
      "test  mean loss=45.99405236891475\n",
      "epoch 4000\n",
      "train mean loss=20.844157008248082\n",
      "test  mean loss=48.342015166385316\n",
      "epoch 4100\n",
      "train mean loss=20.079134691231726\n",
      "test  mean loss=44.281579190850486\n",
      "epoch 4200\n",
      "train mean loss=20.014713012150317\n",
      "test  mean loss=50.45500404981229\n",
      "epoch 4300\n",
      "train mean loss=19.80210528070625\n",
      "test  mean loss=49.503399592125746\n",
      "epoch 4400\n",
      "train mean loss=20.110930202402592\n",
      "test  mean loss=51.35309595352669\n"
     ]
    }
   ],
   "source": [
    "# 一度に勾配を求めるバッチのサイズ\n",
    "batchsize = 500\n",
    "# 学習を行う回数\n",
    "n_epoch = 100000\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    # 学習\n",
    "    # バッチサイズに合わせてランダムに切り出す\n",
    "    perm = np.random.permutation(N)\n",
    "    sum_loss = 0\n",
    "    for i in range(0, N, batchsize):\n",
    "        # バッチづくり\n",
    "        x = xp.asarray(x_train[perm[i:i + batchsize]])\n",
    "        t = xp.asarray(y_train[perm[i:i + batchsize]])\n",
    "\n",
    "        # 予測\n",
    "        p = model(x)\n",
    "        \n",
    "        # 誤差の計算\n",
    "        loss = F.mean_squared_error(p, t)\n",
    "\n",
    "        # 誤差を使って最適化\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        # 表示用\n",
    "        sum_loss += float(loss.data) * batchsize\n",
    "    train_loss = sum_loss\n",
    "\n",
    "    # Epoch毎の評価\n",
    "    sum_loss = 0\n",
    "    for i in range(0, N_test, batchsize):\n",
    "        #　バッチづくり\n",
    "        x = xp.asarray(x_test[i:i + batchsize])\n",
    "        t = xp.asarray(y_test[i:i + batchsize])\n",
    "        \n",
    "        # 予測\n",
    "        p = model(x)\n",
    "        \n",
    "        # 誤差の計算\n",
    "        loss = F.mean_squared_error(p, t)\n",
    "        sum_loss += float(loss.data) * batchsize\n",
    "    test_loss = sum_loss\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        elapsed_time = time.time() - start\n",
    "        print (\"lean elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "\n",
    "        print('epoch', epoch)\n",
    "        print('train mean loss={}'.format(train_loss / N))\n",
    "        print('test  mean loss={}'.format(test_loss / N_test))\n",
    "        model.to_cpu()\n",
    "        # 破壊的なので注意\n",
    "        with open('datas/context2params_{0:07d}.pickle'.format(epoch), 'wb') as o:\n",
    "            pickle.dump(model, o)\n",
    "        model.to_gpu(gpu_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを保存しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GPUで動かしていたらCPUに戻してくる\n",
    "model.to_cpu()\n",
    "# 破壊的なので注意\n",
    "with open('datas/context2params.pickle', 'wb') as o:\n",
    "    pickle.dump(model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#　モデルの読み込みに使う。\n",
    "with open('datas/context2params.pickle', 'rb') as i:\n",
    "    model = pickle.load(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 実際の使い方\n",
    "# contexts_testからnumpy 配列として読み出してmodelに渡す\n",
    "x = contexts_test.values.astype(xp.float32)\n",
    "# modelの返り値はVariable型になっているので.dataでnumpy.array型に戻す。\n",
    "pred = pd.DataFrame(model(x).data, dtype=xp.float32)\n",
    "\n",
    "# 音声生成が使いやすい形式のファイルに書き出す\n",
    "# CSV\n",
    "pred.to_csv(test_path+'.param', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xp.array([[0 for i in range(7)]], dtype=xp.float32)\n",
    "plt.bar(range(27), model(x).data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最初は持ってないから疑似学習・評価データを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 疑似データ生成\n",
    "train_data_len = 50\n",
    "np.random.seed(0)\n",
    "contexts_train = pd.DataFrame()\n",
    "contexts_train['phoneme0'] = np.random.randint(0,20, size = train_data_len)\n",
    "contexts_train['phoneme1'] = np.random.randint(0,20, size = train_data_len)\n",
    "contexts_train['phoneme2'] = np.random.randint(0,20, size = train_data_len)\n",
    "contexts_train['accent_len'] = np.random.randint(0,20, size = train_data_len)\n",
    "contexts_train['accent_pos'] = np.random.randint(0,20, size = train_data_len)\n",
    "contexts_train['accent_type'] = np.random.randint(0,20, size = train_data_len)\n",
    "contexts_train['frame_num'] = np.random.randint(0,20, size = train_data_len)\n",
    "contexts_train['f0'] = np.random.rand(train_data_len)\n",
    "for i in range(26):\n",
    "    contexts_train['mcep'+str(i)] = np.random.rand(train_data_len)\n",
    "\n",
    "contexts_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最初は持ってないから疑似テストデータを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_len = 1000\n",
    "contexts_test = pd.DataFrame()\n",
    "contexts_test['phoneme0'] = np.random.randint(0,20, size = test_data_len)\n",
    "contexts_test['phoneme1'] = np.random.randint(0,20, size = test_data_len)\n",
    "contexts_test['phoneme2'] = np.random.randint(0,20, size = test_data_len)\n",
    "contexts_test['accent_len'] = np.random.randint(0,20, size = test_data_len)\n",
    "contexts_test['accent_pos'] = np.random.randint(0,20, size = test_data_len)\n",
    "contexts_test['accent_type'] = np.random.randint(0,20, size = test_data_len)\n",
    "contexts_test['frame_num'] = np.random.randint(0,20, size = test_data_len)\n",
    "\n",
    "contexts_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
