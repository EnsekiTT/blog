{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 諸々インポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chainer\n",
    "from chainer import Chain\n",
    "from chainer import Variable\n",
    "from chainer import training, report\n",
    "from chainer import optimizers, iterators\n",
    "from chainer.training import extensions\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "cuda.get_device_from_id(0).use()\n",
    "xp = cuda.cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generatorのクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Chain):\n",
    "    def __init__(self, z_dim, wscale=0.02):\n",
    "        w = chainer.initializers.Normal(wscale)\n",
    "        super(Generator, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1=L.Linear(z_dim, 3 * 3 * 512)\n",
    "            \n",
    "            self.dc1=L.Deconvolution2D(512, 256, 2, stride=2, pad=1, initialW=w)\n",
    "            self.dc2=L.Deconvolution2D(256, 128, 2, stride=2, pad=1, initialW=w)\n",
    "            self.dc3=L.Deconvolution2D(128, 64, 2, stride=2, pad=1, initialW=w)\n",
    "            self.dc4=L.Deconvolution2D(64, 3, 7, stride=3, pad=1, initialW=w)\n",
    "            \n",
    "            self.bn1=L.BatchNormalization(512)\n",
    "            self.bn2=L.BatchNormalization(256)\n",
    "            self.bn3=L.BatchNormalization(128)\n",
    "            self.bn4=L.BatchNormalization(64)\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        h = self.l1(z)\n",
    "        h = F.reshape(h, (z.shape[0], 512, 3, 3))\n",
    "        \n",
    "        h1 = F.relu(self.bn1(h))\n",
    "        h2 = F.relu(self.bn2(self.dc1(h1)))\n",
    "        h3 = F.relu(self.bn3(self.dc2(h2)))\n",
    "        h4 = F.relu(self.bn4(self.dc3(h3)))\n",
    "        x = F.sigmoid(self.dc4(h4))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminatorのクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(h, sigma=0.2):\n",
    "    xp = cuda.get_array_module(h.data)\n",
    "    if chainer.config.train:\n",
    "        return h + sigma * xp.random.randn(*h.shape)\n",
    "    else:\n",
    "        return h\n",
    "\n",
    "class Discriminator(Chain):\n",
    "    def __init__(self, wscale=0.02):\n",
    "        w = chainer.initializers.Normal(wscale)\n",
    "        super(Discriminator, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.c1=L.Convolution2D(3, 64, 3, stride=3, pad=1, initialW=w)\n",
    "            self.c2=L.Convolution2D(64, 128, 2, stride=2, pad=1, initialW=w)\n",
    "            self.c3=L.Convolution2D(128, 256, 2, stride=2, pad=1, initialW=w)\n",
    "            self.c4=L.Convolution2D(256, 512, 2, stride=2, pad=1, initialW=w)\n",
    "            \n",
    "            self.l1=L.Linear(3 * 3 * 512, 2)\n",
    "            \n",
    "            self.bn1=L.BatchNormalization(128)\n",
    "            self.bn2=L.BatchNormalization(256)\n",
    "            self.bn3=L.BatchNormalization(512)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h = add_noise(x)\n",
    "        h1 = F.leaky_relu(self.c1(h))\n",
    "        h2 = F.leaky_relu(self.bn1(self.c2(h1)))\n",
    "        h3 = F.leaky_relu(self.bn2(self.c3(h2)))\n",
    "        h4 = F.leaky_relu(self.bn3(self.c4(h3)))\n",
    "        y = self.l1(h4)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updaterのクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANUpdater(training.StandardUpdater):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.gen, self.dis = kwargs.pop('models')\n",
    "        super(GANUpdater, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def dis_loss(self, y_fake, y_real):\n",
    "        batch_size = len(y_fake)\n",
    "        real_loss = F.sum(F.softplus(-y_real)) / batch_size\n",
    "        fake_loss = F.sum(F.softplus(y_fake)) / batch_size\n",
    "        loss = real_loss + fake_loss\n",
    "        report({'loss': loss}, self.dis)\n",
    "        return loss\n",
    "    \n",
    "    def gen_loss(self, y_fake):\n",
    "        batch_size = len(y_fake)\n",
    "        loss = F.sum(F.softplus(-y_fake)) / batch_size\n",
    "        report({'loss': loss}, self.gen)\n",
    "        return loss\n",
    "    \n",
    "    def update_core(self):\n",
    "        gen_optimizer = self.get_optimizer('gen')\n",
    "        dis_optimizer = self.get_optimizer('dis')\n",
    "        \n",
    "        batch = self.get_iterator('main').next()\n",
    "        x_real = Variable(self.converter(batch, self.device))\n",
    "        batch_size = len(x_real)\n",
    "        \n",
    "        y_real = dis(x_real)\n",
    "        \n",
    "        z = xp.random.uniform(-1, 1, (batch_size, self.gen.z_dim))\n",
    "        z = z.astype(dtype=xp.float32)\n",
    "        x_fake = gen(z)\n",
    "        y_fake = dis(x_fake)\n",
    "        \n",
    "        dis_optimizer.update(self.dis_loss, y_fake, y_real)\n",
    "        gen_optimizer.update(self.gen_loss, y_fake)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表示用のクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(gen, rows, cols, dst):\n",
    "    @training.make_extension()\n",
    "    def make_image(trainer):\n",
    "        n_images = rows * cols\n",
    "        z = xp.random.uniform(-1, 1, (rows*cols, gen.z_dim))\n",
    "        z = z.astype(dtype=xp.float32)\n",
    "        with chainer.using_config('train', False):\n",
    "            x = gen(z)\n",
    "        x = cuda.to_cpu(x.data)\n",
    "\n",
    "        x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n",
    "        _, _, H, W = x.shape\n",
    "        x = x.reshape((rows, cols, 3, H, W))\n",
    "        x = x.transpose(0, 3, 1, 4, 2)\n",
    "        x = x.reshape((rows * H, cols * W, 3))\n",
    "        \n",
    "        preview_dir = '{}/preview'.format(dst)\n",
    "        preview_path = preview_dir +\\\n",
    "            '/image{:0>8}.png'.format(trainer.updater.iteration)\n",
    "        if not os.path.exists(preview_dir):\n",
    "            os.makedirs(preview_dir)\n",
    "        Image.fromarray(x).save(preview_path)\n",
    "    return make_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       iteration   gen/loss    dis/loss    elapsed_time\n",
      "\u001b[J2           1000        13.3756     0.267901    20.786        \n",
      "\u001b[J4           2000        12.7655     0.149555    41.255        \n",
      "\u001b[J6           3000        14.9482     0.14894     61.7251       \n",
      "\u001b[J8           4000        15.342      0.11814     82.1239       \n",
      "\u001b[J10          5000        16.2367     0.119011    102.618       \n",
      "\u001b[J12          6000        16.6022     0.174672    123.764       \n",
      "\u001b[J14          7000        16.0269     0.195657    144.691       \n",
      "\u001b[J16          8000        16.5522     0.145074    165.941       \n",
      "\u001b[J18          9000        14.9671     0.1396      186.859       \n",
      "\u001b[J20          10000       18.3422     0.15351     207.442       \n",
      "\u001b[J22          11000       16.2164     0.129818    228.309       \n",
      "\u001b[J24          12000       15.551      0.13664     249.102       \n",
      "\u001b[J26          13000       18.3611     0.188278    270.192       \n",
      "\u001b[J28          14000       17.0132     0.168595    290.929       \n",
      "\u001b[J30          15000       18.259      0.178302    311.729       \n",
      "\u001b[J32          16000       15.1288     0.128828    332.395       \n",
      "\u001b[J34          17000       20.4095     0.173024    353.301       \n",
      "\u001b[J36          18000       17.599      0.188849    374.079       \n",
      "\u001b[J38          19000       16.5853     0.239268    394.749       \n",
      "\u001b[J40          20000       15.8191     0.338163    415.376       \n",
      "\u001b[J42          21000       13.4684     0.290753    435.919       \n",
      "\u001b[J44          22000       13.7896     0.335703    456.481       \n",
      "\u001b[J46          23000       12.8833     0.253867    477.1         \n",
      "\u001b[J48          24000       13.9465     0.252995    497.754       \n",
      "\u001b[J50          25000       14.49       0.267896    518.331       \n",
      "\u001b[J52          26000       13.6651     0.242465    539.037       \n",
      "\u001b[J54          27000       13.2914     0.279119    559.706       \n",
      "\u001b[J56          28000       13.6215     0.281352    580.599       \n",
      "\u001b[J58          29000       13.4849     0.303531    601.364       \n",
      "\u001b[J60          30000       12.8233     0.309068    622.194       \n",
      "\u001b[J62          31000       12.3873     0.26814     642.949       \n",
      "\u001b[J64          32000       12.9712     0.256832    664.135       \n",
      "\u001b[J66          33000       13.3367     0.28853     685.575       \n",
      "\u001b[J68          34000       12.6603     0.357552    707.936       \n",
      "\u001b[J70          35000       13.0059     0.328712    730.507       \n",
      "\u001b[J72          36000       12.5079     0.307092    751.106       \n",
      "\u001b[J74          37000       13.9432     0.316756    771.702       \n"
     ]
    }
   ],
   "source": [
    "gen = Generator(100)\n",
    "dis = Discriminator()\n",
    "gen.to_gpu()\n",
    "dis.to_gpu()\n",
    "\n",
    "gen_opt = optimizers.Adam()\n",
    "gen_opt.setup(gen)\n",
    "dis_opt = optimizers.Adam()\n",
    "dis_opt.setup(dis)\n",
    "\n",
    "imgs = []\n",
    "dataset_path = os.environ.get(key=\"DATA_SET_DIR\")\n",
    "dataset_dir = os.path.join(dataset_path, 'cifar10/cifar-10-batches-bin')\n",
    "n_train = 10000\n",
    "for i in range(5):\n",
    "    dataset_path = os.path.join(dataset_dir, 'data_batch_'+str(i+1)+'.bin')\n",
    "    with open(dataset_path, 'rb') as cifar10:\n",
    "        for i in range(n_train):\n",
    "            data = cifar10.read(3073)\n",
    "            values = list(struct.unpack(\"3073b\", data))\n",
    "            label = values[0]\n",
    "            img = np.asarray(values[1:], dtype=np.uint8).reshape(32,32,3, order='F')/255.\n",
    "            imgs.append(img)\n",
    "\n",
    "imgs = np.asarray(imgs, dtype=np.float32)\n",
    "X = imgs.reshape(n_train*5, 3, 32, 32)\n",
    "\n",
    "train = iterators.SerialIterator(X, 100)\n",
    "\n",
    "updater = GANUpdater(models=(gen, dis), \n",
    "                     iterator=train, \n",
    "                     optimizer={'gen': gen_opt, 'dis': dis_opt}, \n",
    "                     device=0)\n",
    "\n",
    "trainer = training.Trainer(updater, (1000, 'epoch'), out='result')\n",
    "\n",
    "snapshot_interval = (10, 'epoch')\n",
    "display_interval = (1000, 'iteration')\n",
    "trainer.extend(extensions.LogReport(trigger=display_interval))\n",
    "trainer.extend(extensions.PrintReport([\n",
    "    'epoch', 'iteration', 'gen/loss', 'dis/loss', 'elapsed_time'\n",
    "]), trigger=display_interval)\n",
    "\n",
    "trainer.extend(image(gen, 10, 10, 'result'),trigger=snapshot_interval)\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c6c1e838c72e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 表示用\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROTATE_270\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# 表示用\n",
    "deff = X[0] * 255\n",
    "a = Image.fromarray(np.uint8(deff.reshape(32,32,3)))\n",
    "a = a.transpose(Image.ROTATE_270)\n",
    "a.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
