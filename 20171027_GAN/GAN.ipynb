{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import Chain\n",
    "from chainer import Variable, optimizers\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(Chain):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__(\n",
    "            l1=L.Linear(z_dim, 3 * 3 * 512),\n",
    "            \n",
    "            dc1=L.Deconvolution2D(512, 256, 2, stride=2, pad=1, ),\n",
    "            dc2=L.Deconvolution2D(256, 128, 2, stride=2, pad=1, ),\n",
    "            dc3=L.Deconvolution2D(128, 64, 2, stride=2, pad=1, ),\n",
    "            dc4=L.Deconvolution2D(64, 1, 3, stride=3, pad=1,),\n",
    "            \n",
    "            bn1=L.BatchNormalization(512),\n",
    "            bn2=L.BatchNormalization(256),\n",
    "            bn3=L.BatchNormalization(128),\n",
    "            bn4=L.BatchNormalization(64),\n",
    "        )\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        h = self.l1(z)\n",
    "        h = F.reshape(h, (z.data.shape[0], 512, 3, 3))\n",
    "        \n",
    "        h1 = F.relu(self.bn1(h))\n",
    "        h2 = F.relu(self.bn2(self.dc1(h1)))\n",
    "        h3 = F.relu(self.bn3(self.dc2(h2)))\n",
    "        h4 = F.relu(self.bn4(self.dc3(h3)))\n",
    "        x = self.dc4(h4)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(Chain):\n",
    "    def __init__(self, ):\n",
    "        super(Discriminator, self).__init__(\n",
    "            c1=L.Convolution2D(1, 64, 3, stride=3, pad=1, ),\n",
    "            c2=L.Convolution2D(64, 128, 2, stride=2, pad=1, ),\n",
    "            c3=L.Convolution2D(128, 256, 2, stride=2, pad=1, ),\n",
    "            c4=L.Convolution2D(256, 512, 2, stride=2, pad=1, ),\n",
    "            \n",
    "            l1=L.Linear(3 * 3 * 512, 2),\n",
    "            \n",
    "            bn1=L.BatchNormalization(128),\n",
    "            bn2=L.BatchNormalization(256),\n",
    "            bn3=L.BatchNormalization(512),\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.c1(x))\n",
    "        h2 = F.relu(self.bn1(self.c2(h1)))\n",
    "        h3 = F.relu(self.bn2(self.c3(h2)))\n",
    "        h4 = F.relu(self.bn3(self.c4(h3)))\n",
    "        y = self.l1(h4)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, gen, dis):\n",
    "        self.gen = gen\n",
    "        self.dis = dis\n",
    "        self.z_dim = gen.z_dim\n",
    "        \n",
    "    def fit(self, X, epochs=100, batch_size=1000, plotting=True):\n",
    "        self.X = X\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.plotting = plotting\n",
    "        \n",
    "        n_train = X.shape[0]\n",
    "        o_gen = optimizers.Adam()\n",
    "        o_dis = optimizers.Adam()\n",
    "        \n",
    "        o_gen.setup(self.gen)\n",
    "        o_dis.setup(self.dis)\n",
    "        \n",
    "        self.loss = []\n",
    "        for epoch in range(epochs):\n",
    "            perm = np.random.permutation(n_train)\n",
    "            sum_loss_of_dis = np.float32(0)\n",
    "            sum_loss_of_gen = np.float32(0)\n",
    "            \n",
    "            for i in range(int(n_train / batch_size)):\n",
    "                z = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "                z = z.astype(dtype=np.float32)\n",
    "                \n",
    "                # 生成する\n",
    "                x = self.gen(z)\n",
    "                # 贋作か予測する(贋作側)\n",
    "                y1 = self.dis(x)\n",
    "                \n",
    "                loss_gen = F.softmax_cross_entropy(y1, Variable(np.zeros(batch_size, dtype=np.int32)))\n",
    "                loss_dis = F.softmax_cross_entropy(y1, Variable(np.ones(batch_size, dtype=np.int32)))\n",
    "                \n",
    "                idx = perm[i * batch_size:(i + 1) * batch_size]\n",
    "                x_data = self.X[idx]\n",
    "                \n",
    "                # 贋作か予測する（真作側）\n",
    "                y2 = self.dis(x_data)\n",
    "                \n",
    "                loss_dis += F.softmax_cross_entropy(y2, Variable(np.zeros(batch_size, dtype=np.int32)))\n",
    "                \n",
    "                self.dis.cleargrads()\n",
    "                loss_dis.backward()\n",
    "                o_dis.update()\n",
    "                \n",
    "                self.gen.cleargrads()\n",
    "                loss_gen.backward()\n",
    "                o_gen.update()\n",
    "                \n",
    "                sum_loss_of_dis += loss_dis.data\n",
    "                sum_loss_of_gen += loss_gen.data\n",
    "                \n",
    "            print('epoch-{epoch}\\tloss\\tdiscreminator-{sum_loss_of_dis:.3f}\\tgenerator-{sum_loss_of_gen:.3f}'.format(**locals()))\n",
    "            \n",
    "            self.loss.append([sum_loss_of_gen, sum_loss_of_dis])\n",
    "            \n",
    "            if plotting:\n",
    "                plt.figure(figsize=(12, 12))\n",
    "                n_row = 3\n",
    "                s = n_row ** 2\n",
    "                z = Variable(np.random.uniform(-1, 1, 100 * s).reshape(-1, 100).astype(np.float32))\n",
    "                x = self.gen(z)\n",
    "                y = self.dis(x)\n",
    "                y = F.softmax(y).data\n",
    "                x = x.data.reshape(-1, 28, 28)\n",
    "                for i, xx in enumerate(x):\n",
    "                    plt.subplot(n_row, n_row, i + 1)\n",
    "                    plt.imshow(xx, interpolation=\"nearest\", cmap=\"gray\")\n",
    "                    plt.axis('off')\n",
    "                    plt.title('True Prob {0:.3f}'.format(y[i][0]))\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('epoch-{epoch}.png'.format(**locals()), dip=100)\n",
    "                plt.close('all')\n",
    "        print(self.loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "epoch-0\tloss\tdiscreminator-6.483\tgenerator-394.438\n",
      "epoch-1\tloss\tdiscreminator-0.275\tgenerator-482.044\n",
      "epoch-2\tloss\tdiscreminator-0.126\tgenerator-537.606\n",
      "epoch-3\tloss\tdiscreminator-0.050\tgenerator-580.688\n",
      "epoch-4\tloss\tdiscreminator-0.038\tgenerator-588.821\n",
      "epoch-5\tloss\tdiscreminator-0.026\tgenerator-609.267\n",
      "epoch-6\tloss\tdiscreminator-0.018\tgenerator-633.259\n",
      "epoch-7\tloss\tdiscreminator-0.012\tgenerator-654.502\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3899c185e694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e45385711097>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, epochs, batch_size, plotting)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleargrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mloss_dis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mo_dis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad, enable_double_backprop)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \"\"\"\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enable_backprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_double_backprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36m_backward_main\u001b[0;34m(self, retain_grad)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m             gxs = func.backward_accumulate(\n\u001b[0;32m--> 953\u001b[0;31m                 target_input_indexes, out_grad, in_grad)\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mbackward_accumulate\u001b[0;34m(self, target_input_indexes, grad_outputs, grad_inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;31m# The default implementation uses backward(). You can override this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# method without using backward().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mgxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_input_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mlen_gxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, indexes, grad_outputs)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cudnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpander\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             self.mean, self.inv_std)\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_owned_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Retain all inputs by default in old-style functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_input_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.0/envs/ml/lib/python3.6/site-packages/chainer/functions/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 gx = (gamma * self.inv_std)[expander] * (\n\u001b[0;32m--> 178\u001b[0;31m                     gy - (x_hat * ggamma[expander] + gbeta[expander]) * inv_m)\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 gx = cuda.elementwise(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen = Generator(100)\n",
    "dis = Discriminator()\n",
    "\n",
    "data = fetch_mldata('MNIST original')\n",
    "X = data['data']\n",
    "n_train = X.shape[0]\n",
    "X = np.array(X, dtype=np.float32)\n",
    "X /= 255.\n",
    "X = X.reshape(n_train, 1, 28, 28)\n",
    "\n",
    "print(\"Start!\")\n",
    "trainer = Trainer(gen, dis)\n",
    "trainer.fit(X, batch_size=1000, epochs=1000)\n",
    "\n",
    "df_loss = pd.DataFrame(trainer.loss)\n",
    "df_loss.to_csv('loss.csv')\n",
    "\n",
    "gen.to_cpu()\n",
    "dis.to_cpu()\n",
    "\n",
    "with open('generator.model', 'wb') as w:\n",
    "    pickle.dump(gen, w)\n",
    "\n",
    "with open('discriminator.model', 'wb') as w:\n",
    "    pickle.dump(dis, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
