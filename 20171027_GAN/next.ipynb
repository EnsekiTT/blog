{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import chainer\n",
    "from chainer import Chain\n",
    "from chainer import Variable\n",
    "from chainer import training, report\n",
    "from chainer import optimizers, iterators\n",
    "from chainer.training import extensions\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "cuda.get_device_from_id(0).use()\n",
    "xp = cuda.cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Chain):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__(\n",
    "            l1=L.Linear(z_dim, 3 * 3 * 512),\n",
    "            \n",
    "            dc1=L.Deconvolution2D(512, 256, 2, stride=2, pad=1, ),\n",
    "            dc2=L.Deconvolution2D(256, 128, 2, stride=2, pad=1, ),\n",
    "            dc3=L.Deconvolution2D(128, 64, 2, stride=2, pad=1, ),\n",
    "            dc4=L.Deconvolution2D(64, 1, 3, stride=3, pad=1,),\n",
    "            \n",
    "            bn1=L.BatchNormalization(512),\n",
    "            bn2=L.BatchNormalization(256),\n",
    "            bn3=L.BatchNormalization(128),\n",
    "            bn4=L.BatchNormalization(64),\n",
    "        )\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "    def __call__(self, z):\n",
    "        h = self.l1(z)\n",
    "        h = F.reshape(h, (z.shape[0], 512, 3, 3))\n",
    "        \n",
    "        h1 = F.relu(self.bn1(h))\n",
    "        h2 = F.relu(self.bn2(self.dc1(h1)))\n",
    "        h3 = F.relu(self.bn3(self.dc2(h2)))\n",
    "        h4 = F.relu(self.bn4(self.dc3(h3)))\n",
    "        x = F.sigmoid(self.dc4(h4))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Chain):\n",
    "    def __init__(self, ):\n",
    "        super(Discriminator, self).__init__(\n",
    "            c1=L.Convolution2D(1, 64, 3, stride=3, pad=1, ),\n",
    "            c2=L.Convolution2D(64, 128, 2, stride=2, pad=1, ),\n",
    "            c3=L.Convolution2D(128, 256, 2, stride=2, pad=1, ),\n",
    "            c4=L.Convolution2D(256, 512, 2, stride=2, pad=1, ),\n",
    "            \n",
    "            l1=L.Linear(3 * 3 * 512, 2),\n",
    "            \n",
    "            bn1=L.BatchNormalization(128),\n",
    "            bn2=L.BatchNormalization(256),\n",
    "            bn3=L.BatchNormalization(512),\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.c1(x))\n",
    "        h2 = F.relu(self.bn1(self.c2(h1)))\n",
    "        h3 = F.relu(self.bn2(self.c3(h2)))\n",
    "        h4 = F.relu(self.bn3(self.c4(h3)))\n",
    "        y = self.l1(h4)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANUpdater(training.StandardUpdater):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.gen, self.dis = kwargs.pop('models')\n",
    "        super(GANUpdater, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def dis_loss(self, y_fake, y_real):\n",
    "        batch_size = len(y_fake)\n",
    "        real_loss = F.sum(F.softplus(-y_real)) / batch_size\n",
    "        fake_loss = F.sum(F.softplus(y_fake)) / batch_size\n",
    "        loss = real_loss + fake_loss\n",
    "        report({'loss': loss}, self.dis)\n",
    "        return loss\n",
    "    \n",
    "    def gen_loss(self, y_fake):\n",
    "        batch_size = len(y_fake)\n",
    "        loss = F.sum(F.softplus(-y_fake)) / batch_size\n",
    "        report({'loss': loss}, self.gen)\n",
    "        return loss\n",
    "    \n",
    "    def update_core(self):\n",
    "        gen_optimizer = self.get_optimizer('gen')\n",
    "        dis_optimizer = self.get_optimizer('dis')\n",
    "        \n",
    "        batch = self.get_iterator('main').next()\n",
    "        x_real = Variable(self.converter(batch, self.device))\n",
    "        batch_size = len(x_real)\n",
    "        \n",
    "        y_real = dis(x_real)\n",
    "        \n",
    "        z = xp.random.uniform(-1, 1, (batch_size, self.gen.z_dim))\n",
    "        z = z.astype(dtype=xp.float32)\n",
    "        x_fake = gen(z)\n",
    "        y_fake = dis(x_fake)\n",
    "        \n",
    "        dis_optimizer.update(self.dis_loss, y_fake, y_real)\n",
    "        gen_optimizer.update(self.gen_loss, y_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(gen, rows, cols, dst):\n",
    "    @training.make_extension()\n",
    "    def make_image(trainer):\n",
    "        n_images = rows * cols\n",
    "        z = xp.random.uniform(-1, 1, (rows*cols, gen.z_dim))\n",
    "        z = z.astype(dtype=xp.float32)\n",
    "        with chainer.using_config('train', False):\n",
    "            x = gen(z)\n",
    "        x = cuda.to_cpu(x.data)\n",
    "\n",
    "        x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n",
    "        _, _, H, W = x.shape\n",
    "        x = x.reshape((rows, cols, 1, H, W))\n",
    "        x = x.transpose(0, 3, 1, 4, 2)\n",
    "        x = x.reshape((rows * H, cols * W))\n",
    "        \n",
    "        preview_dir = '{}/preview'.format(dst)\n",
    "        preview_path = preview_dir +\\\n",
    "            '/image{:0>8}.png'.format(trainer.updater.iteration)\n",
    "        if not os.path.exists(preview_dir):\n",
    "            os.makedirs(preview_dir)\n",
    "        Image.fromarray(x).save(preview_path)\n",
    "    return make_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(100)\n",
    "dis = Discriminator()\n",
    "gen.to_gpu()\n",
    "dis.to_gpu()\n",
    "\n",
    "gen_opt = optimizers.Adam()\n",
    "gen_opt.setup(gen)\n",
    "dis_opt = optimizers.Adam()\n",
    "dis_opt.setup(dis)\n",
    "\n",
    "data = fetch_mldata('MNIST original')\n",
    "X = data['data']\n",
    "n_train = X.shape[0]\n",
    "X = np.array(X, dtype=np.float32)\n",
    "X /= 255.\n",
    "X = X.reshape(n_train, 1, 28, 28)\n",
    "train = iterators.SerialIterator(X, 100)\n",
    "\n",
    "updater = GANUpdater(models=(gen, dis), \n",
    "                     iterator=train, \n",
    "                     optimizer={'gen': gen_opt, 'dis': dis_opt}, \n",
    "                     device=0)\n",
    "\n",
    "trainer = training.Trainer(updater, (1000, 'epoch'), out='result')\n",
    "\n",
    "snapshot_interval = (100, 'epoch')\n",
    "display_interval = (1000, 'iteration')\n",
    "trainer.extend(extensions.LogReport(trigger=display_interval))\n",
    "trainer.extend(extensions.PrintReport([\n",
    "    'epoch', 'iteration', 'gen/loss', 'dis/loss',\n",
    "]), trigger=display_interval)\n",
    "\n",
    "trainer.extend(image(gen, 10, 10, 'result'),trigger=snapshot_interval)\n",
    "\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
